{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import math\nimport json\nimport requests\nimport itertools\nimport numpy as np\nimport time\nimport datetime\nimport pandas as pd \nimport numpy as np\nimport os","execution_count":27,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df=pd.read_csv('/kaggle/input/reddit-data-balanced/reddit_data_balanced.csv')","execution_count":28,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":29,"outputs":[{"output_type":"execute_result","execution_count":29,"data":{"text/plain":"   Unnamed: 0                                              title  \\\n0           0                                     HELP HELP TEST   \n1           1                  Lets have a conversation Randians   \n2           2  Forest guards ordered to watch over python tha...   \n3           3  Engineering pass-outs from Shitty colleges (Ti...   \n4           4     The Constitution, as ABVP would have it. [Old]   \n\n           flair  \n0  [R]eddiquette  \n1  [R]eddiquette  \n2  Non-Political  \n3       AskIndia  \n4       Politics  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>title</th>\n      <th>flair</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>HELP HELP TEST</td>\n      <td>[R]eddiquette</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>Lets have a conversation Randians</td>\n      <td>[R]eddiquette</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>Forest guards ordered to watch over python tha...</td>\n      <td>Non-Political</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>Engineering pass-outs from Shitty colleges (Ti...</td>\n      <td>AskIndia</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>The Constitution, as ABVP would have it. [Old]</td>\n      <td>Politics</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"contractions_dict = { \"ain't\": \"are not\",\"'s\":\" is\",\"aren't\": \"are not\",\n                     \"can't\": \"cannot\",\"can't've\": \"cannot have\",\n                     \"'cause\": \"because\",\"could've\": \"could have\",\"couldn't\": \"could not\",\n                     \"couldn't've\": \"could not have\", \"didn't\": \"did not\",\"doesn't\": \"does not\",\n                     \"don't\": \"do not\",\"hadn't\": \"had not\",\"hadn't've\": \"had not have\",\n                     \"hasn't\": \"has not\",\"haven't\": \"have not\",\"he'd\": \"he would\",\n                     \"he'd've\": \"he would have\",\"he'll\": \"he will\", \"he'll've\": \"he will have\",\n                     \"how'd\": \"how did\",\"how'd'y\": \"how do you\",\"how'll\": \"how will\",\n                     \"I'd\": \"I would\", \"I'd've\": \"I would have\",\"I'll\": \"I will\",\n                     \"I'll've\": \"I will have\",\"I'm\": \"I am\",\"I've\": \"I have\", \"isn't\": \"is not\",\n                     \"it'd\": \"it would\",\"it'd've\": \"it would have\",\"it'll\": \"it will\",\n                     \"it'll've\": \"it will have\", \"let's\": \"let us\",\"ma'am\": \"madam\",\n                     \"mayn't\": \"may not\",\"might've\": \"might have\",\"mightn't\": \"might not\", \n                     \"mightn't've\": \"might not have\",\"must've\": \"must have\",\"mustn't\": \"must not\",\n                     \"mustn't've\": \"must not have\", \"needn't\": \"need not\",\n                     \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\"oughtn't\": \"ought not\",\n                     \"oughtn't've\": \"ought not have\",\"shan't\": \"shall not\",\"sha'n't\": \"shall not\",\n                     \"shan't've\": \"shall not have\",\"she'd\": \"she would\",\"she'd've\": \"she would have\",\n                     \"she'll\": \"she will\", \"she'll've\": \"she will have\",\"should've\": \"should have\",\n                     \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\",\"so've\": \"so have\",\n                     \"that'd\": \"that would\",\"that'd've\": \"that would have\", \"there'd\": \"there would\",\n                     \"there'd've\": \"there would have\", \"they'd\": \"they would\",\n                     \"they'd've\": \"they would have\",\"they'll\": \"they will\",\n                     \"they'll've\": \"they will have\", \"they're\": \"they are\",\"they've\": \"they have\",\n                     \"to've\": \"to have\",\"wasn't\": \"was not\",\"we'd\": \"we would\",\n                     \"we'd've\": \"we would have\",\"we'll\": \"we will\",\"we'll've\": \"we will have\",\n                     \"we're\": \"we are\",\"we've\": \"we have\", \"weren't\": \"were not\",\"what'll\": \"what will\",\n                     \"what'll've\": \"what will have\",\"what're\": \"what are\", \"what've\": \"what have\",\n                     \"when've\": \"when have\",\"where'd\": \"where did\", \"where've\": \"where have\",\n                     \"who'll\": \"who will\",\"who'll've\": \"who will have\",\"who've\": \"who have\",\n                     \"why've\": \"why have\",\"will've\": \"will have\",\"won't\": \"will not\",\n                     \"won't've\": \"will not have\", \"would've\": \"would have\",\"wouldn't\": \"would not\",\n                     \"wouldn't've\": \"would not have\",\"y'all\": \"you all\", \"y'all'd\": \"you all would\",\n                     \"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\n                     \"y'all've\": \"you all have\", \"you'd\": \"you would\",\"you'd've\": \"you would have\",\n                     \"you'll\": \"you will\",\"you'll've\": \"you will have\", \"you're\": \"you are\",\n                     \"you've\": \"you have\"}\n\n# Regular expression for finding contractions\ncontractions_re=re.compile('(%s)' % '|'.join(contractions_dict.keys()))\n\n# Function for expanding contractions\ndef expand_contractions(text,contractions_dict=contractions_dict):\n  def replace(match):\n    return contractions_dict[match.group(0)]\n  return contractions_re.sub(replace, text)\n\ndf['title']=df['title'].apply(lambda x:expand_contractions(x))","execution_count":30,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import re\n# data cleaning: remove URL's from train and test\ndf['clean_title'] = df['title'].apply(lambda x: re.sub(r'http\\S+', '', x))\n\n# remove handles (@user)\ndf['clean_title'] = df['clean_title'].apply(lambda x: re.sub(\"@[\\w]*\", '', x))\n# test['clean_tweet'] = test['clean_tweet'].apply(lambda x: re.sub(\"@[\\w]*\", '', x))\n  \n# remove punctuation marks\npunctuation = '.,\\'!\"#$%&()*+-/:;<=>?@[\\\\]^_`{|}~'\n\ndf['clean_title'] = df['clean_title'].apply(lambda x: ''.join(ch for ch in x if ch not in set(punctuation)))\n\n# convert text to lowercase\ndf['clean_title'] = df['clean_title'].str.lower()\n\n# remove numbers\ndf['clean_title'] = df['clean_title'].str.replace(\"[0-9]\", \" \")\n","execution_count":31,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.Series(df['flair'].factorize()[0]).value_counts()","execution_count":19,"outputs":[{"output_type":"execute_result","execution_count":19,"data":{"text/plain":"3     10000\n2     10000\n1     10000\n12     8000\n11     8000\n7      8000\n13     5000\n9      5000\n8      5000\n0      5000\n10     3500\n6      3500\n5      3500\n4      3500\ndtype: int64"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['category_id'] = df['flair'].factorize()[0]\ncategory_id_df = df[['flair', 'category_id']].drop_duplicates().sort_values('category_id')\ncategory_to_id = dict(category_id_df.values)\nid_to_category = dict(category_id_df[['category_id', 'flair']].values)\ndf.head()","execution_count":32,"outputs":[{"output_type":"execute_result","execution_count":32,"data":{"text/plain":"   Unnamed: 0                                              title  \\\n0           0                                     HELP HELP TEST   \n1           1                  Lets have a conversation Randians   \n2           2  Forest guards ordered to watch over python tha...   \n3           3  Engineering pass-outs from Shitty colleges (Ti...   \n4           4     The Constitution, as ABVP would have it. [Old]   \n\n           flair                                        clean_title  \\\n0  [R]eddiquette                                     help help test   \n1  [R]eddiquette                  lets have a conversation randians   \n2  Non-Political  forest guards ordered to watch over python tha...   \n3       AskIndia  engineering passouts from shitty colleges tier...   \n4       Politics         the constitution as abvp would have it old   \n\n   category_id  \n0            0  \n1            0  \n2            1  \n3            2  \n4            3  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>title</th>\n      <th>flair</th>\n      <th>clean_title</th>\n      <th>category_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>HELP HELP TEST</td>\n      <td>[R]eddiquette</td>\n      <td>help help test</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>Lets have a conversation Randians</td>\n      <td>[R]eddiquette</td>\n      <td>lets have a conversation randians</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>Forest guards ordered to watch over python tha...</td>\n      <td>Non-Political</td>\n      <td>forest guards ordered to watch over python tha...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>Engineering pass-outs from Shitty colleges (Ti...</td>\n      <td>AskIndia</td>\n      <td>engineering passouts from shitty colleges tier...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>The Constitution, as ABVP would have it. [Old]</td>\n      <td>Politics</td>\n      <td>the constitution as abvp would have it old</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"category_id_df","execution_count":21,"outputs":[{"output_type":"execute_result","execution_count":21,"data":{"text/plain":"                 flair  category_id\n0        [R]eddiquette            0\n2        Non-Political            1\n3             AskIndia            2\n4             Politics            3\n5          Photography            4\n6                 Food            5\n9       Demonetization            6\n10    Business/Finance            7\n12               other            8\n13              Sports            9\n14     Not in English.           10\n17  Science/Technology           11\n34      Policy/Economy           12\n65         Coronavirus           13","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>flair</th>\n      <th>category_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[R]eddiquette</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Non-Political</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>AskIndia</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Politics</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Photography</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Food</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Demonetization</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Business/Finance</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>other</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>Sports</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>Not in English.</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>Science/Technology</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>Policy/Economy</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>65</th>\n      <td>Coronavirus</td>\n      <td>13</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfTransformer\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import LinearSVC\nfrom sklearn.model_selection import cross_val_score","execution_count":33,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# X_train, X_test, y_train, y_test = train_test_split(df['title'], df['flair'], random_state = 0)\n# count_vect = CountVectorizer()\n# X_counts = count_vect.fit_transform(df['title'])\n# tfidf_transformer = TfidfTransformer()\n# X_tfidf = tfidf_transformer.fit_transform(X_counts)\n# # X_train, X_test, y_train, y_test = train_test_split(X_tfidf, df['flair'], random_state = 0)\n# clf = LinearSVC().fit(X_tfidf[0:70000], df['flair'][0:70000])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\nvectorizer = TfidfVectorizer()\nX_counts=vectorizer.fit(df['clean_title'])\nvector = vectorizer.transform(df['clean_title'])\n","execution_count":34,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = LinearSVC().fit(vector[0:70000], df['flair'][0:70000])","execution_count":35,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# clf = MultinomialNB().fit(vector[0:70000], df['flair'][0:70000])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# clf = LogisticRegression(dual=False, solver='lbfgs', random_state=0, class_weight='balanced').fit(vector[0:70000], df['flair'][0:70000])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from sklearn.svm import SVC\n# from sklearn.model_selection import GridSearchCV\n# parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}\n# clf = GridSearchCV(estimator = SVC(), param_grid=parameters)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# clf.fit(vector[0:70000], df['flair'][0:70000])\n# clf.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from sklearn.svm import SVC\n# clf = SVC().fit(vector[0:70000], df['flair'][0:70000])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred=clf.predict(vector[70000:])","execution_count":36,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report\nclassification_report(df['flair'][70000:], y_pred, output_dict=True)","execution_count":37,"outputs":[{"output_type":"execute_result","execution_count":37,"data":{"text/plain":"{'AskIndia': {'precision': 0.45410821643286575,\n  'recall': 0.5728008088978767,\n  'f1-score': 0.5065951263134362,\n  'support': 1978},\n 'Business/Finance': {'precision': 0.562394127611519,\n  'recall': 0.5883047844063792,\n  'f1-score': 0.5750577367205542,\n  'support': 1693},\n 'Coronavirus': {'precision': 0.7169287696577243,\n  'recall': 0.7352941176470589,\n  'f1-score': 0.7259953161592506,\n  'support': 1054},\n 'Demonetization': {'precision': 0.6202860858257477,\n  'recall': 0.645466847090663,\n  'f1-score': 0.6326259946949602,\n  'support': 739},\n 'Food': {'precision': 0.6806596701649176,\n  'recall': 0.6666666666666666,\n  'f1-score': 0.6735905044510386,\n  'support': 681},\n 'Non-Political': {'precision': 0.3167225682798275,\n  'recall': 0.32338551859099807,\n  'f1-score': 0.32001936577099976,\n  'support': 2044},\n 'Not in English.': {'precision': 0.6736641221374046,\n  'recall': 0.4909596662030598,\n  'f1-score': 0.5679806918744972,\n  'support': 719},\n 'Photography': {'precision': 0.5908479138627187,\n  'recall': 0.5876840696117804,\n  'f1-score': 0.589261744966443,\n  'support': 747},\n 'Policy/Economy': {'precision': 0.4714765100671141,\n  'recall': 0.51183970856102,\n  'f1-score': 0.4908296943231441,\n  'support': 1647},\n 'Politics': {'precision': 0.5245332175423361,\n  'recall': 0.5881207400194742,\n  'f1-score': 0.5545099839338996,\n  'support': 2054},\n 'Science/Technology': {'precision': 0.5088443396226415,\n  'recall': 0.5304240934234788,\n  'f1-score': 0.5194101715317484,\n  'support': 1627},\n 'Sports': {'precision': 0.7898406374501992,\n  'recall': 0.7789783889980354,\n  'f1-score': 0.7843719090009891,\n  'support': 1018},\n '[R]eddiquette': {'precision': 0.24783362218370883,\n  'recall': 0.140748031496063,\n  'f1-score': 0.17953546767106088,\n  'support': 1016},\n 'other': {'precision': 0.2101010101010101,\n  'recall': 0.10579857578840285,\n  'f1-score': 0.14073071718538566,\n  'support': 983},\n 'accuracy': 0.5134444444444445,\n 'macro avg': {'precision': 0.5263029150671239,\n  'recall': 0.5190337155286397,\n  'f1-score': 0.5186081731855291,\n  'support': 18000},\n 'weighted avg': {'precision': 0.5025122508157933,\n  'recall': 0.5134444444444445,\n  'f1-score': 0.5045220130935955,\n  'support': 18000}}"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}
